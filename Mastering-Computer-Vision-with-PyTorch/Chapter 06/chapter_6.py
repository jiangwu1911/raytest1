# -*- coding: utf-8 -*-
"""Chapter 6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14CuScVg-f7gE5fNqg-arMzpef9ELeiJD

# Virtual Environment Setup
"""

# Transform and Compose
from torchvision import transforms


transform_pipeline = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
])

# RandomHorizontalFlip
transforms.RandomHorizontalFlip(p=0.5)

# RandomVerticalFlip
transforms.RandomVerticalFlip(p=0.5)

# ColorJitter
transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0)

# RandomRotation
degrees = 10
transforms.RandomRotation(degrees, expand=False, center=None, fill=None)

# RandomResizedCrop
size = [100, 100]
transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(3. / 4., 4. / 3.), interpolation=2)

# RandomAffine
degrees = 10
transforms.RandomAffine(degrees, translate=None, scale=None, shear=None)

# GaussianBlur
kernel_size = (3, 3)
transforms.GaussianBlur(kernel_size, sigma=(0.1, 2.0))

# RandomCrop
size = [100, 100]
transforms.RandomCrop(size, padding=None, pad_if_needed=False, fill=0, padding_mode='constant')

# RandomErasing
transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False)

# RandomPerspective
transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3)

# CenterCrop
size = [100, 100]
transforms.CenterCrop(size)

# Create Dummy image
import cv2
import numpy as np

# Create a black image
image = np.zeros((256, 256, 3), dtype=np.uint8)

# Draw a rectangle
cv2.rectangle(image, (50, 50), (250, 250), (255, 0, 0), -1)

# Draw a circle
cv2.circle(image, (128, 128), 50, (0, 255, 0), -1)

# Convert to PIL

image = Image.fromarray(image)

# RandomHorizontalFlip

# Flips the image horizontally with a given probability (p=1 in this example).
import matplotlib.pyplot as plt
from torchvision import transforms
from PIL import Image

# RandomHorizontalFlip
random_horizontal_flip = transforms.RandomHorizontalFlip(p=1)
h_flipped_image = random_horizontal_flip(image)


# Display
plt.imshow(h_flipped_image)
plt.title('RandomHorizontalFlip')
plt.show()

# RandomVerticalFlip
# Flips the image vertically with a given probability (p=1 in this example).
import matplotlib.pyplot as plt
from torchvision import transforms
from PIL import Image

# RandomVerticalFlip
random_vertical_flip = transforms.RandomVerticalFlip(p=1)
flipped_image = random_vertical_flip(image)


# Display
plt.imshow(flipped_image)
plt.title('RandomVerticalFlip')
plt.axis('off')
plt.show()

# ColorJitter
# Randomly changes the brightness, contrast, saturation, and hue of an image.
import matplotlib.pyplot as plt
from torchvision import transforms

# ColorJitter
color_jitter = transforms.ColorJitter(brightness=0.5, contrast=0.5, hue=0.5)
jittered_image = color_jitter(image)
# Display
plt.imshow(jittered_image)
plt.title('ColorJitter')
plt.show()

# RandomRotation
# Rotates the image by a random angle.
import matplotlib.pyplot as plt
from torchvision import transforms

# RandomRotation
random_rotation = transforms.RandomRotation(degrees=(0, 180))
rotated_image = random_rotation(image)


# Display
plt.imshow(rotated_image)
plt.title('RandomRotation')
plt.axis('off')
plt.show()

# RandomResizedCrop
# Crops the given image to a random size and aspect ratio.
import matplotlib.pyplot as plt
from torchvision import transforms


# RandomResizedCrop
random_resized_crop = transforms.RandomResizedCrop(size=(224, 224))
resized_cropped_image = random_resized_crop(image)


# Display
plt.imshow(resized_cropped_image)
plt.title('RandomResizedCrop')
plt.axis('off')
plt.show()

# RandomAffine
# Applies random affine transformations to the image.
import matplotlib.pyplot as plt
from torchvision import transforms

# RandomAffine
random_affine = transforms.RandomAffine(degrees=(0, 360), translate=(0.1, 0.1), scale=(0.7, 1.3), shear=(0, 20))
affine_image = random_affine(image)
# Display
plt.imshow(affine_image)
plt.title('RandomAffine')
plt.axis('off')
plt.show()

# GaussianBlur
# Blurs the image with a Gaussian filter.
import matplotlib.pyplot as plt
from torchvision import transforms

# GaussianBlur
gaussian_blur = transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5))
blurred_image = gaussian_blur(image)


# Display
plt.imshow(blurred_image)
plt.title('GaussianBlur')
plt.axis('off')
plt.show()

# RandomCrop
# Crops the given image at a random location.
import matplotlib.pyplot as plt
from torchvision import transforms
# RandomCrop
random_crop = transforms.RandomCrop(size=(100, 100))
cropped_image = random_crop(image)


# Display
plt.imshow(cropped_image)
plt.title('RandomCrop')
plt.axis('off')
plt.show()

# RandomErasing
# Randomly erases a rectangle region in an image.
import matplotlib.pyplot as plt
from torchvision import transforms

# Convert to tensor for RandomErasing
to_tensor = transforms.ToTensor()
image_tensor = to_tensor(image)


# RandomErasing
random_erasing = transforms.RandomErasing(p=1, scale=(0.1, 0.33), ratio=(0.3, 3.3), value='random')
erased_image_tensor = random_erasing(image_tensor)


# Convert back to image to display
to_pil = transforms.ToPILImage()
erased_image = to_pil(erased_image_tensor)


plt.imshow(erased_image)
plt.title('RandomErasing')
plt.axis('off')
plt.show()

# RandomPerspective
# Performs a random perspective transformation of the image with a given probability.
import matplotlib.pyplot as plt
from torchvision import transforms


# RandomPerspective
random_perspective = transforms.RandomPerspective(distortion_scale=0.6, p=1, interpolation=3)
perspective_image = random_perspective(image)


# Display
plt.imshow(perspective_image)
plt.title('RandomPerspective')
plt.axis('off')
plt.show()

# CenterCrop
# Crops the given image at the center.
import matplotlib.pyplot as plt
from torchvision import transforms

# CenterCrop
center_crop = transforms.CenterCrop(size=(100, 100))
cropped_image = center_crop(image)


# Display
plt.imshow(cropped_image)
plt.title('CenterCrop')
plt.axis('off')
plt.show()

# Complete Example
# Letâ€™s now use all the augmentations together to generate different images from a single input image
import matplotlib.pyplot as plt
from torchvision import transforms


# Combined Augmentations
all_augmentations = transforms.Compose([
    transforms.CenterCrop(size=(100, 100)),
    transforms.RandomPerspective(distortion_scale=0.6, p=1, interpolation=3),
    transforms.RandomApply([transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5))], p=0.5),
    transforms.RandomAffine(degrees=(0, 360), translate=(0.1, 0.1), scale=(0.7, 1.3), shear=(0, 20)),
    transforms.RandomResizedCrop(size=(224, 224)),
    transforms.RandomRotation(degrees=(0, 180)),
    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),
    transforms.RandomVerticalFlip(p=0.5),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ToTensor(),
    transforms.RandomErasing(p=0.5, scale=(0.1, 0.33), ratio=(0.3, 3.3), value='random'),
])


# Function to display images
def show_augmented_images(image_path, num_images=5):
    plt.figure(figsize=(15, 3))

    for i in range(num_images):
        augmented_image = all_augmentations(image)
        ax = plt.subplot(1, num_images, i + 1)
        ax.imshow(transforms.ToPILImage()(augmented_image))
        ax.axis('off')
    plt.show()


show_augmented_images('test.png')

# Additional augmentations for CIFAR-10 training data

import torch
import torchvision

transform_augmented = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])


# Use the augmented transform for the training dataset
trainset_augmented = torchvision.datasets.CIFAR10(root='./data', train=True,
                                                  download=True, transform=transform_augmented)
trainloader_augmented = torch.utils.data.DataLoader(trainset_augmented, batch_size=4,
                                                    shuffle=True)

# Updated code with new augmentations on the CIFAR-10 dataset
import torch
import torchvision
import torchvision.transforms as transforms


# Set up the transform to normalize the data
transform = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])


# Load the CIFAR-10 dataset
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)


testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False)


classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')


# Define the neural network
import torch.nn as nn
import torch.nn.functional as F


class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)


    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


net = SimpleCNN()


# Compile the model with torch.compile for PyTorch 2.0
compiled_net = torch.compile(net)


# Set up the loss function and optimizer
import torch.optim as optim


criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(compiled_net.parameters(), lr=0.001, momentum=0.9)


# Train the network
for epoch in range(5):  # Loop over the dataset multiple times
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        optimizer.zero_grad()
        outputs = compiled_net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        if i % 2000 == 1999:    # Print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0


print('Finished Training')


# Test the network on the test data
correct = 0
total = 0
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = compiled_net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))

